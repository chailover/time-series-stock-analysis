{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "This notebook is dedicated to modeling the time series data. We will split the data into training and testing sets, train various models such as ARIMA, SARIMA, and LSTM, and tune hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-libraries"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-data"
   },
   "outputs": [],
   "source": [
    "# Load the processed data\n",
    "data = pd.read_csv('../data/processed/processed_data.csv', parse_dates=['date'], index_col='date')\n",
    "data = data.asfreq('D')  # Ensure the data is daily frequency\n",
    "data.fillna(method='ffill', inplace=True)  # Forward fill missing values\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "split-data"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = data[0:train_size], data[train_size:]\n",
    "\n",
    "print(f'Train size: {len(train)}')\n",
    "print(f'Test size: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train-arima"
   },
   "outputs": [],
   "source": [
    "# Train ARIMA model\n",
    "arima_model = ARIMA(train, order=(5, 1, 0))\n",
    "arima_result = arima_model.fit()\n",
    "\n",
    "# Forecast\n",
    "arima_forecast = arima_result.forecast(steps=len(test))\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train.index, train, label='Train')\n",
    "plt.plot(test.index, test, label='Test')\n",
    "plt.plot(test.index, arima_forecast, label='ARIMA Forecast', color='red')\n",
    "plt.legend()\n",
    "plt.title('ARIMA Model Forecast')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate-arima"
   },
   "outputs": [],
   "source": [
    "# Evaluate ARIMA model\n",
    "mae = mean_absolute_error(test, arima_forecast)\n",
    "rmse = np.sqrt(mean_squared_error(test, arima_forecast))\n",
    "\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train-lstm"
   },
   "outputs": [],
   "source": [
    "# Prepare data for LSTM\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 10\n",
    "X_train, y_train = create_dataset(train.values, time_step)\n",
    "X_test, y_test = create_dataset(test.values, time_step)\n",
    "\n",
    "# Reshape input to be [samples, time steps, features]\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Build LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(LSTM(50, return_sequences=False))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train LSTM model\n",
    "lstm_model.fit(X_train, y_train, epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate-lstm"
   },
   "outputs": [],
   "source": [
    "# Evaluate LSTM model\n",
    "lstm_forecast = lstm_model.predict(X_test)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test.index, test, label='Test')\n",
    "plt.plot(test.index[time_step:], lstm_forecast, label='LSTM Forecast', color='green')\n",
    "plt.legend()\n",
    "plt.title('LSTM Model Forecast')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "final-evaluation"
   },
   "outputs": [],
   "source": [
    "# Final evaluation of LSTM model\n",
    "lstm_mae = mean_absolute_error(y_test, lstm_forecast)\n",
    "lstm_rmse = np.sqrt(mean_squared_error(y_test, lstm_forecast))\n",
    "\n",
    "print(f'LSTM MAE: {lstm_mae}')\n",
    "print(f'LSTM RMSE: {lstm_rmse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}